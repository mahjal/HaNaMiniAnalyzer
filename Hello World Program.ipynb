{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6572174f",
   "metadata": {},
   "source": [
    "# Import Essentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PUGNN import SW, HomoDataset, HomoDataReader, BoostedDataLoader, Trainer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da7261",
   "metadata": {},
   "source": [
    "# Specify the `output` and `input` directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10484625",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory  = \"/eos/user/m/mjalalva/Run1/June4/\"\n",
    "output_directory = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b4e6a",
   "metadata": {},
   "source": [
    "# Define a model and some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d336044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GraphConv, MLP, global_add_pool, GATv2Conv, LayerNorm, global_mean_pool\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PUModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_features, GNN=GraphConv):\n",
    "        super(PUModel, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        self.conv1 = GNN(in_channels, hidden_channels, edge_dim=1, add_self_loops=False)\n",
    "        self.norm1 = LayerNorm(hidden_channels)\n",
    "        self.mlp1  = MLP([hidden_channels + num_features, 2*hidden_channels, 2*hidden_channels], norm='layer_norm')\n",
    "        \n",
    "        self.conv2 = GNN(hidden_channels, hidden_channels, edge_dim=1, add_self_loops=False)\n",
    "        self.norm2 = LayerNorm(hidden_channels)\n",
    "        self.mlp2  = MLP([3*hidden_channels + num_features, 2*hidden_channels, hidden_channels, hidden_channels//2, out_channels], norm='layer_norm')\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, adj, features, batch = data.x, data.adj_t, torch.reshape(data.features, (-1, self.num_features)), data.batch\n",
    "        \n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, adj)\n",
    "        x = self.norm1(x)\n",
    "        x = x.relu()\n",
    "        \n",
    "        g = self.mlp1(torch.cat([global_mean_pool(x, batch), features], dim=1))\n",
    "    \n",
    "        x = self.conv2(x, adj)\n",
    "        x = self.norm2(x)\n",
    "        x = x.relu()\n",
    "\n",
    "        g = self.mlp2(torch.cat([global_mean_pool(x, batch), g, features], dim=1))\n",
    "        \n",
    "        return g\n",
    "    \n",
    "class Bias(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        return\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        return (input-target).mean()\n",
    "    \n",
    "class MAPE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        return\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        return (abs(input-target)/target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ebe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PUModel(in_channels=12, hidden_channels=150, num_features=7, out_channels=1, GNN=GATv2Conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e3c56",
   "metadata": {},
   "source": [
    "# Make an Instance of `SW` Class with Your `DataSet` and a `DataLoader` Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "software1 = SW(input_directory, output_directory, name='pu-test')\n",
    "sample_metadata = dict(zip(\n",
    "    map(str, list(range(20, 81))), # Range on PU values\n",
    "    np.ones(61) * 10               # Number of events at a given PU\n",
    "))\n",
    "\n",
    "software1.set_dataset(HomoDataset,      # Your Dataset Type\n",
    "                      sample_metadata, \n",
    "                      HomoDataReader()  # A Data Reader Function\n",
    "                     )\n",
    "\n",
    "software1.set_loader(BoostedDataLoader, # Your Dataloader Type\n",
    "                     loading_workers=4,\n",
    "                     batch_size=4,\n",
    "                     num_workers=16\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4678e5",
   "metadata": {},
   "source": [
    "# Enter into the `TrainerScope` of Your `SW`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d971c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with software1.trainer_scope(Trainer) as pu_trainer:\n",
    "    pu_trainer.set(model)\n",
    "    res = pu_trainer.train(\n",
    "        max_epochs=50, optimizer=torch.optim.RAdam,\n",
    "        optimizer_args=dict(lr=5e-3),\n",
    "        loss_fn=torch.nn.L1Loss,\n",
    "        metrics=[MAPE(), Bias()], select_topk=5,\n",
    "        lr_scheduler=torch.optim.lr_scheduler.MultiStepLR,\n",
    "        lr_scheduler_args=dict(milestones=[7, 15, 25, 35], gamma=0.06),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0123e35d",
   "metadata": {},
   "source": [
    "# After Training, Let's Enter into the `AnalyzerScope`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca959282",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eval_model = PUModel(in_channels=12, hidden_channels=150, num_features=7, out_channels=1, GNN=GATv2Conv)\n",
    "\n",
    "with software1.analyzer_scope() as pu_analyzer:\n",
    "    pu_analyzer(eval_model, state_dicts, torch.nn.L1Loss())\n",
    "    \n",
    "    best_model = pu_analyzer.model\n",
    "    res_plot   = pu_analyzer.residual_plot()\n",
    "    metrics    = pu_analyzer.apply_metrics([Bias(), MAPE(), MAE(), MSE()])\n",
    "    dist_plots = pu_analyzer.distribution_plots()\n",
    "    LLERes     = pu_analyzer.rangeLLE(30,60)\n",
    "    \n",
    "    no_verts   = pu_analyzer.extract_feature(0, 7)\n",
    "    comparing  = pu_analyzer.compare(\n",
    "        # Here, you can add the outputs as follows:\n",
    "        # `model2` = (model2_summary.y, model2_summary.yhat)\n",
    "        # `model3` = ...\n",
    "        NV = (pu_analyzer.y, nv)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee84ec",
   "metadata": {},
   "source": [
    "## Distribution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc3df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plots.heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39847b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plots.histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_plots.kdeplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ce45a",
   "metadata": {},
   "source": [
    "## Residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d398bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d961a1",
   "metadata": {},
   "source": [
    "## Compare the model with another models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing.plot   # Visualize the comparasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1e69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing.R2     # R2 factor of model itself and with other models if they exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d0738",
   "metadata": {},
   "source": [
    "## Log-likelihood Estimation through a Given Range of $<PU>=L\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee7bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLERes.plot  # The plot of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLERes.estimated_pu       # Estimated <PU> by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d7eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLERes.true_pu            # Expected or real <PU>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bf16ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLERes.lower_bond_error   # Lower-bond error of estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ada3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLERes.upper_bond_error   # Upper-bond error of estimation"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}